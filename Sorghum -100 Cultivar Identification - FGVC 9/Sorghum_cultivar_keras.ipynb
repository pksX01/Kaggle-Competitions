{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.applications import efficientnet_v2\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.version' from '/Users/rudra/ml-env/env/lib/python3.9/site-packages/tensorflow/_api/v2/version/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/rudra/Tech/ML_Work/Datasets/archive')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path  = Path('/Users/rudra/Tech/ML_Work/Datasets/archive')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path/'train_cultivar_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>cultivar</th>\n",
       "      <th>file_path</th>\n",
       "      <th>is_exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-16__12-24-20-930.jpeg</td>\n",
       "      <td>PI_257599</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-02__16-48-57-866.jpeg</td>\n",
       "      <td>PI_154987</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-12__13-18-07-707.jpeg</td>\n",
       "      <td>PI_92270</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-06-22__13-18-06-841.jpeg</td>\n",
       "      <td>PI_152651</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-06-26__12-56-48-642.jpeg</td>\n",
       "      <td>PI_176766</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image   cultivar  \\\n",
       "0  2017-06-16__12-24-20-930.jpeg  PI_257599   \n",
       "1  2017-06-02__16-48-57-866.jpeg  PI_154987   \n",
       "2  2017-06-12__13-18-07-707.jpeg   PI_92270   \n",
       "3  2017-06-22__13-18-06-841.jpeg  PI_152651   \n",
       "4  2017-06-26__12-56-48-642.jpeg  PI_176766   \n",
       "\n",
       "                                           file_path  is_exist  \n",
       "0  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True  \n",
       "1  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True  \n",
       "2  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True  \n",
       "3  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True  \n",
       "4  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.is_exist.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17755 validated image filenames belonging to 100 classes.\n",
      "Found 4438 validated image filenames belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=path/'train',\n",
    "    x_col='image',\n",
    "    y_col='cultivar',\n",
    "    class_mode='sparse',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=path/'train',\n",
    "    x_col='image',\n",
    "    y_col='cultivar',\n",
    "    class_mode='sparse',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:Learning rate reduction mode <built-in function min> is unknown, fallback to auto mode.\n"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', verbose=1, patience=3)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filepath='sorghum_keras_model.h5', monitor='val_accuracy', verbose=1, save_freq='epoch', \n",
    "                                                    save_best_only=True, save_weights_only=True, period=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, mode=min, patience=3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n",
      "52609024/52606240 [==============================] - 7s 0us/step\n",
      "52617216/52606240 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = efficientnet_v2.EfficientNetV2B3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b3 (Function  (None, 8, 8, 1536)       12930622  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1536)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               153700    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,084,322\n",
      "Trainable params: 12,975,106\n",
      "Non-trainable params: 109,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "output = base_model(inputs)\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dense(100, activation='softmax')(output)\n",
    "\n",
    "model = keras.Model(inputs, output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 23:31:01.813181: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555/555 [==============================] - ETA: 0s - loss: 2.4992 - accuracy: 0.3543 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 07:04:07.054772: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54912, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 27266s 49s/step - loss: 2.4992 - accuracy: 0.3543 - val_loss: 1.5162 - val_accuracy: 0.5491 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 1.0469 - accuracy: 0.6857\n",
      "Epoch 2: val_accuracy improved from 0.54912 to 0.72713, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 1783s 3s/step - loss: 1.0469 - accuracy: 0.6857 - val_loss: 0.8721 - val_accuracy: 0.7271 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.7977\n",
      "Epoch 3: val_accuracy improved from 0.72713 to 0.73006, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 1872s 3s/step - loss: 0.6481 - accuracy: 0.7977 - val_loss: 0.8959 - val_accuracy: 0.7301 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8568\n",
      "Epoch 4: val_accuracy improved from 0.73006 to 0.84205, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 1874s 3s/step - loss: 0.4459 - accuracy: 0.8568 - val_loss: 0.5043 - val_accuracy: 0.8420 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.8848\n",
      "Epoch 5: val_accuracy improved from 0.84205 to 0.87494, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 1936s 3s/step - loss: 0.3621 - accuracy: 0.8848 - val_loss: 0.3907 - val_accuracy: 0.8749 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.3004 - accuracy: 0.9050\n",
      "Epoch 6: val_accuracy did not improve from 0.87494\n",
      "555/555 [==============================] - 1878s 3s/step - loss: 0.3004 - accuracy: 0.9050 - val_loss: 0.4041 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 0.9143\n",
      "Epoch 7: val_accuracy improved from 0.87494 to 0.88846, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 1668s 3s/step - loss: 0.2754 - accuracy: 0.9143 - val_loss: 0.3518 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9266\n",
      "Epoch 8: val_accuracy improved from 0.88846 to 0.88982, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 1620s 3s/step - loss: 0.2285 - accuracy: 0.9266 - val_loss: 0.3392 - val_accuracy: 0.8898 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.9271\n",
      "Epoch 9: val_accuracy improved from 0.88982 to 0.89950, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 1769s 3s/step - loss: 0.2205 - accuracy: 0.9271 - val_loss: 0.3083 - val_accuracy: 0.8995 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.9431\n",
      "Epoch 10: val_accuracy improved from 0.89950 to 0.91595, saving model to sorghum_keras_model.h5\n",
      "555/555 [==============================] - 1916s 3s/step - loss: 0.1786 - accuracy: 0.9431 - val_loss: 0.2636 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9446\n",
      "Epoch 11: val_accuracy did not improve from 0.91595\n",
      "555/555 [==============================] - 1565s 3s/step - loss: 0.1685 - accuracy: 0.9446 - val_loss: 0.3122 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.9480\n",
      "Epoch 12: val_accuracy did not improve from 0.91595\n",
      "555/555 [==============================] - 1516s 3s/step - loss: 0.1635 - accuracy: 0.9480 - val_loss: 0.3160 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "555/555 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9489\n",
      "Epoch 13: val_accuracy did not improve from 0.91595\n",
      "555/555 [==============================] - 1867s 3s/step - loss: 0.1598 - accuracy: 0.9489 - val_loss: 0.3070 - val_accuracy: 0.9015 - lr: 0.0010\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_generator, validation_data=valid_generator, epochs=EPOCHS, callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Sorghum_keras_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 16:20:25.330170: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-01 16:20:25.330433: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/Users/rudra/Tech/ML_Work/Sorghum_keras_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_df.cultivar)\n",
    "train_df['target'] = le.transform(train_df.cultivar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>cultivar</th>\n",
       "      <th>file_path</th>\n",
       "      <th>is_exist</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-16__12-24-20-930.jpeg</td>\n",
       "      <td>PI_257599</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-02__16-48-57-866.jpeg</td>\n",
       "      <td>PI_154987</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-12__13-18-07-707.jpeg</td>\n",
       "      <td>PI_92270</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-06-22__13-18-06-841.jpeg</td>\n",
       "      <td>PI_152651</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-06-26__12-56-48-642.jpeg</td>\n",
       "      <td>PI_176766</td>\n",
       "      <td>../input/sorghum-id-fgvc-9/train_images/2017-0...</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image   cultivar  \\\n",
       "0  2017-06-16__12-24-20-930.jpeg  PI_257599   \n",
       "1  2017-06-02__16-48-57-866.jpeg  PI_154987   \n",
       "2  2017-06-12__13-18-07-707.jpeg   PI_92270   \n",
       "3  2017-06-22__13-18-06-841.jpeg  PI_152651   \n",
       "4  2017-06-26__12-56-48-642.jpeg  PI_176766   \n",
       "\n",
       "                                           file_path  is_exist  target  \n",
       "0  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True      73  \n",
       "1  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True      29  \n",
       "2  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True      99  \n",
       "3  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True       6  \n",
       "4  ../input/sorghum-id-fgvc-9/train_images/2017-0...      True      50  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23639 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_filenames = os.listdir(path/'test')\n",
    "test_df = pd.DataFrame({'filename' : test_filenames})\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    directory = path/'test',\n",
    "    x_col = 'filename',\n",
    "    y_col = None,\n",
    "    class_mode = None,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(train_df.cultivar.unique())\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 16:26:07.541950: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-01 16:26:08.258395: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_generator)\n",
    "pred_idx = np.argmax(preds, axis=1)\n",
    "#predictions = [classes[i] for i in pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df['cultivar'] = predictions\n",
    "test_df['cultivar'] = le.inverse_transform(list(pred_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.filename = test_df.filename.map(lambda x: x.split('.jpeg')[0] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cultivar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1838798748.png</td>\n",
       "      <td>PI_218112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42096263.png</td>\n",
       "      <td>PI_152860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316490365.png</td>\n",
       "      <td>PI_329299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1091940264.png</td>\n",
       "      <td>PI_152828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>470001726.png</td>\n",
       "      <td>PI_329301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename   cultivar\n",
       "0  1838798748.png  PI_218112\n",
       "1    42096263.png  PI_152860\n",
       "2   316490365.png  PI_329299\n",
       "3  1091940264.png  PI_152828\n",
       "4   470001726.png  PI_329301"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a03200ae361ba04b33dfbb7697ae27a1e19c2e9be6094bfaf79232177e8f3033"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
